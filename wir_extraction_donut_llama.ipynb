{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JAshinflame/AI-Agents/blob/main/wir_extraction_donut_llama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCbB9lcDLbuw"
      },
      "source": [
        "# ðŸ“¦ Install dependencies\n",
        "!pip install transformers torch torchvision torchaudio pillow requests --quiet"
      ],
      "id": "eCbB9lcDLbuw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wmcw2i5Lbux"
      },
      "source": [
        "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
        "from PIL import Image\n",
        "import json, requests\n",
        "from pathlib import Path\n",
        "\n",
        "# === Step 1: Donut Extraction ===\n",
        "processor = DonutProcessor.from_pretrained('naver-clova-ix/donut-base-finetuned-docvqa')\n",
        "model = VisionEncoderDecoderModel.from_pretrained('naver-clova-ix/donut-base-finetuned-docvqa')\n",
        "\n",
        "wir_image_path = Path('/mnt/data/Test 10 WIR.png')\n",
        "assert wir_image_path.exists(), f\"WIR image not found: {wir_image_path}\"\n",
        "print('âœ… Image found:', wir_image_path)\n",
        "\n",
        "image = Image.open(wir_image_path).convert('RGB')\n",
        "pixel_values = processor(image, return_tensors='pt').pixel_values\n",
        "\n",
        "task_prompt = '<s_docvqa><s_question>Extract all key details from this WIR form.</s_question><s_answer>'\n",
        "decoder_input_ids = processor.tokenizer(task_prompt, add_special_tokens=False, return_tensors='pt').input_ids\n",
        "\n",
        "outputs = model.generate(\n",
        "    pixel_values,\n",
        "    decoder_input_ids=decoder_input_ids,\n",
        "    max_length=512,\n",
        "    num_beams=3,\n",
        "    repetition_penalty=2.5,\n",
        "    no_repeat_ngram_size=3,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "raw_text = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "print('--- Raw Donut Output (first 1000 chars) ---\\n', raw_text[:1000])"
      ],
      "id": "-wmcw2i5Lbux",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCXoQ0IyLbux"
      },
      "source": [
        "# === Step 2: Clean & Structure with Llama/Mistral via Ollama ===\n",
        "import subprocess\n",
        "\n",
        "# Choose model: 'llama3' or 'mistral'\n",
        "OLLAMA_MODEL = 'llama3'\n",
        "\n",
        "prompt = f'''\n",
        "You are an AI document parser. Clean and extract structured information from the raw text below.\n",
        "Identify and normalize exactly these fields:\n",
        "- Project\n",
        "- WIR No\n",
        "- Date\n",
        "- Activity\n",
        "- Contractor\n",
        "- Remarks\n",
        "\n",
        "Output **only valid JSON** with these keys and their values.\n",
        "\n",
        "--- Raw Text ---\n",
        "{raw_text}\n",
        "'''\n",
        "\n",
        "# Run Ollama model locally\n",
        "result = subprocess.run(\n",
        "    ['ollama', 'run', OLLAMA_MODEL],\n",
        "    input=prompt.encode('utf-8'),\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.PIPE\n",
        ")\n",
        "\n",
        "llm_output = result.stdout.decode('utf-8').strip()\n",
        "print('--- Ollama Output ---\\n', llm_output)\n",
        "\n",
        "# Attempt to parse as JSON\n",
        "try:\n",
        "    structured = json.loads(llm_output)\n",
        "except Exception:\n",
        "    structured = {'raw_response': llm_output}\n",
        "\n",
        "output_path = Path('/mnt/data/wir_extracted_llama_v9.json')\n",
        "with open(output_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(structured, f, indent=2)\n",
        "\n",
        "print('\\nâœ… Saved structured WIR data to:', output_path)"
      ],
      "id": "NCXoQ0IyLbux",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}